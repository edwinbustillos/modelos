# Modelos de IA

Este repositÃ³rio contÃ©m modelos de inteligÃªncia artificial para uso local.

## ğŸ“¥ Como fazer download

### PrÃ©-requisitos

Para trabalhar com este repositÃ³rio que usa Git LFS (Large File Storage), vocÃª precisarÃ¡:

1. **Git** instalado em seu sistema
2. **Git LFS** instalado e configurado

### InstalaÃ§Ã£o do Git LFS

Se vocÃª ainda nÃ£o tem o Git LFS instalado:

```bash
# No macOS (usando Homebrew)
brew install git-lfs

# No Ubuntu/Debian
sudo apt install git-lfs

# No Windows
# Baixe de: https://git-lfs.github.io/
```

### Download do repositÃ³rio

1. **Clone o repositÃ³rio:**
   ```bash
   git clone https://github.com/edwinbustillos/modelos.git
   cd modelos
   ```

2. **Inicialize o Git LFS (se necessÃ¡rio):**
   ```bash
   git lfs install
   ```

3. **Baixe os arquivos grandes:**
   ```bash
   git lfs pull
   ```

## ğŸ“ Estrutura do Projeto

```
modelos/
â”œâ”€â”€ ğŸ“„ README.md                    # Este arquivo
â”œâ”€â”€ ğŸ¤– llama3-small-Q3_K_S.gguf   # Modelo Llama 3 Small (104.33 MB)
â”œâ”€â”€ ğŸ³ Dockerfile                   # ConfiguraÃ§Ã£o Docker
â”œâ”€â”€ ğŸ™ docker-compose.yml          # OrquestraÃ§Ã£o de serviÃ§os
â”œâ”€â”€ ğŸš€ ollama.sh                   # Script unificado (tudo em um!)
â””â”€â”€ ğŸ“ models/                     # DiretÃ³rio para modelos (volume Docker)
```

## ğŸ”§ Uso

### OpÃ§Ã£o 1: Docker (Recomendado)

A maneira mais fÃ¡cil de usar os modelos Ã© com Docker + Ollama + Interface Web:

```bash
# Clone o repositÃ³rio
git clone https://github.com/edwinbustillos/modelos.git
cd modelos

# Execute o setup automÃ¡tico
./ollama.sh start
```

Isso irÃ¡:
- ğŸ³ Construir e iniciar containers Docker
- ğŸ¤– Configurar Ollama com os modelos GGUF  
- ğŸŒ Disponibilizar interface web em http://localhost:3000
- ğŸ“¡ API Ollama em http://localhost:11434

**Comandos disponÃ­veis:**
```bash
./ollama.sh start       # Iniciar todos os serviÃ§os
./ollama.sh stop        # Parar todos os serviÃ§os
./ollama.sh restart     # Reiniciar serviÃ§os
./ollama.sh status      # Verificar status
./ollama.sh logs        # Ver logs em tempo real
./ollama.sh help        # Exibir ajuda completa
```

### OpÃ§Ã£o 2: Uso Direto

Os arquivos `.gguf` sÃ£o modelos quantizados que podem ser usados com:
- **llama.cpp**
- **Ollama**
- **LM Studio** 
- **GPT4All**
- Outras ferramentas compatÃ­veis com o formato GGUF

## âš ï¸ ObservaÃ§Ãµes importantes

- Este repositÃ³rio usa Git LFS para gerenciar arquivos grandes
- Certifique-se de ter o Git LFS instalado antes de clonar
- O download pode demorar dependendo da sua conexÃ£o (arquivo de ~104 MB)
- Os modelos sÃ£o fornecidos "como estÃ£o" para fins de pesquisa e desenvolvimento

## ğŸ“„ LicenÃ§a

Consulte a documentaÃ§Ã£o original dos modelos para informaÃ§Ãµes sobre licenciamento.